{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('genre_300_sample_plot.csv', index_col='id_of_the_film')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features_label(data_df):\n",
    "    return data_df.drop(columns=['genre_of_the_film']), data_df['genre_of_the_film']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_split(df):\n",
    "    X, y = split_features_label(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=42)\n",
    "\n",
    "    X_tr = pd.concat([X_train, y_train], axis=1)\n",
    "    X_tr.to_csv(\"movies_for_svd_train.csv\", index_label='id_of_the_film')\n",
    "    X_te = pd.concat([X_test, y_test], axis=1)\n",
    "    X_te.to_csv(\"movies_for_svd_test.csv\", index_label='id_of_the_film')\n",
    "    \n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train_sc = scaler.transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "    X_train_sc = pd.DataFrame(X_train_sc, columns=X_train.columns, index=X_train.index)\n",
    "    X_test_sc = pd.DataFrame(X_test_sc, columns=X_test.columns, index=X_test.index)\n",
    "    return X_train_sc, X_test_sc, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder_films(encoding_dim, X_tr, X_te):\n",
    "    ncol = X_tr.shape[1]\n",
    "    input_dim = Input(shape = (ncol, ))\n",
    "    encoded1 = Dense(5000, activation = 'relu')(input_dim)\n",
    "    encoded2 = Dense(encoding_dim, activation = 'relu')(encoded1)\n",
    "    decoded1 = Dense(5000, activation = 'relu')(encoded2)\n",
    "    output = Dense(ncol, activation = 'sigmoid')(decoded1)\n",
    "    autoencoder = Model(inputs = input_dim, outputs = output)\n",
    "    autoencoder.compile(optimizer = 'adadelta', loss = 'mean_squared_error')\n",
    "    autoencoder.summary()\n",
    "    autoencoder.fit(X_tr, X_tr, nb_epoch = 1, batch_size = 100, shuffle = False, validation_data = (X_te, X_te))\n",
    "    encoder = Model(inputs = input_dim, outputs = encoded2)\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_train_test_films_to_csv(encoder, X_train_sc, X_test_sc, y_train, y_test, encod_dim):\n",
    "    X_train_encoded = pd.DataFrame(encoder.predict(X_train_sc)).add_prefix('feature_')\n",
    "    X_train_encoded.index = X_train_sc.index\n",
    "    X_train_fin = pd.concat([X_train_encoded, y_train], axis=1)\n",
    "    X_train_fin.to_csv(\"train_compressed_to_\" + str(encod_dim) + \"_features.csv\", index_label='id_of_the_film')\n",
    "\n",
    "    X_test_encoded = pd.DataFrame(encoder.predict(X_test_sc)).add_prefix('feature_')\n",
    "    X_test_encoded.index = X_test_sc.index\n",
    "    X_test_fin = pd.concat([X_test_encoded, y_test], axis=1)\n",
    "    X_test_fin.to_csv(\"test_compressed_to_\" + str(encod_dim) + \"_features.csv\", index_label='id_of_the_film')\n",
    "    return 'hoi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "X_train_sc, X_test_sc, y_train, y_test = scale_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_ae, X_test_ae = train_test_split(X_train_sc, train_size = 0.85, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encod_dim = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 50005)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5000)              250030000 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               2500500   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5000)              2505000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50005)             250075005 \n",
      "=================================================================\n",
      "Total params: 505,110,505\n",
      "Trainable params: 505,110,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2856 samples, validate on 504 samples\n",
      "Epoch 1/1\n",
      "2856/2856 [==============================] - 367s 128ms/step - loss: 0.2496 - val_loss: 0.2496\n",
      "Wall time: 6min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "encoder = build_encoder_films(encod_dim, X_train_ae, X_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encode_train_test_films_to_csv(encoder, X_train_sc, X_test_sc, y_train, y_test, encod_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

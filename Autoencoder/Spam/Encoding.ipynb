{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pd.read_csv('spam_train_bag_of_words.csv', index_col='Unnamed: 0')\n",
    "df_test = pd.read_csv('spam_test_bag_of_words.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>go</th>\n",
       "      <th>jurong</th>\n",
       "      <th>point</th>\n",
       "      <th>crazi</th>\n",
       "      <th>avail</th>\n",
       "      <th>bugi</th>\n",
       "      <th>n</th>\n",
       "      <th>great</th>\n",
       "      <th>world</th>\n",
       "      <th>...</th>\n",
       "      <th>guy_bitch</th>\n",
       "      <th>bitch_act</th>\n",
       "      <th>act_like</th>\n",
       "      <th>like_interest</th>\n",
       "      <th>interest_buy</th>\n",
       "      <th>buy_someth</th>\n",
       "      <th>els_next</th>\n",
       "      <th>week_gave</th>\n",
       "      <th>gave_us</th>\n",
       "      <th>us_free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text1</th>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text2</th>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text3</th>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text4</th>\n",
       "      <td>ham</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text5</th>\n",
       "      <td>spam</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label   go  jurong  point  crazi  avail  bugi    n  great  world  \\\n",
       "text1   ham  0.0       0    0.0    0.0    0.0     0  0.0    0.0    0.0   \n",
       "text2  spam  0.0       0    0.0    0.0    0.0     0  0.0    0.0    0.0   \n",
       "text3   ham  0.0       0    0.0    0.0    0.0     0  0.0    0.0    0.0   \n",
       "text4   ham  0.0       0    0.0    0.0    0.0     0  0.0    0.0    0.0   \n",
       "text5  spam  0.0       0    0.0    0.0    0.0     0  0.0    0.0    0.0   \n",
       "\n",
       "        ...     guy_bitch  bitch_act  act_like  like_interest  interest_buy  \\\n",
       "text1   ...             0          0         0              0             0   \n",
       "text2   ...             0          0         0              0             0   \n",
       "text3   ...             0          0         0              0             0   \n",
       "text4   ...             0          0         0              0             0   \n",
       "text5   ...             0          0         0              0             0   \n",
       "\n",
       "       buy_someth  els_next  week_gave  gave_us  us_free  \n",
       "text1           0         0          0        0        0  \n",
       "text2           0         0          0        0        0  \n",
       "text3           0         0          0        0        0  \n",
       "text4           0         0          0        0        0  \n",
       "text5           0         0          0        0        0  \n",
       "\n",
       "[5 rows x 29155 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1671, 29155)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features_label(data_df, label):\n",
    "    return data_df.drop(columns=[label]), data_df[label]\n",
    "\n",
    "def scale_split(df_train, df_test, label):\n",
    "    X_train, y_train = split_features_label(df_train, label)\n",
    "    X_test, y_test = split_features_label(df_test, label)\n",
    "\n",
    "    scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train_sc = scaler.transform(X_train)\n",
    "    X_test_sc = scaler.transform(X_test)\n",
    "    X_train_sc = pd.DataFrame(X_train_sc, columns=X_train.columns, index=X_train.index)\n",
    "    X_test_sc = pd.DataFrame(X_test_sc, columns=X_test.columns, index=X_test.index)\n",
    "    return X_train_sc, X_test_sc, y_train, y_test\n",
    "\n",
    "def build_encoder_films(encoding_dim, X_tr, X_te):\n",
    "    ncol = X_tr.shape[1]\n",
    "    input_dim = Input(shape = (ncol, ))\n",
    "    encoded1 = Dense(5000, activation = 'relu')(input_dim)\n",
    "    encoded2 = Dense(encoding_dim, activation = 'relu')(encoded1)\n",
    "    decoded1 = Dense(5000, activation = 'relu')(encoded2)\n",
    "    output = Dense(ncol, activation = 'sigmoid')(decoded1)\n",
    "    autoencoder = Model(inputs = input_dim, outputs = output)\n",
    "    autoencoder.compile(optimizer = 'adadelta', loss = 'mean_squared_error')\n",
    "    autoencoder.summary()\n",
    "    autoencoder.fit(X_tr, X_tr, nb_epoch = 1, batch_size = 100, shuffle = False, validation_data = (X_te, X_te))\n",
    "    encoder = Model(inputs = input_dim, outputs = encoded2)\n",
    "    return encoder\n",
    "\n",
    "def encode_train_test_films_to_csv(encoder, X_train_sc, X_test_sc, y_train, y_test, encod_dim):\n",
    "    X_train_encoded = pd.DataFrame(encoder.predict(X_train_sc)).add_prefix('feature_')\n",
    "    X_train_encoded.index = X_train_sc.index\n",
    "    X_train_fin = pd.concat([X_train_encoded, y_train], axis=1)\n",
    "    X_train_fin.to_csv(\"spam_train_ae_compressed_to_\" + str(encod_dim) + \"_features.csv\", index_label='id_of_the_text')\n",
    "\n",
    "    X_test_encoded = pd.DataFrame(encoder.predict(X_test_sc)).add_prefix('feature_')\n",
    "    X_test_encoded.index = X_test_sc.index\n",
    "    X_test_fin = pd.concat([X_test_encoded, y_test], axis=1)\n",
    "    X_test_fin.to_csv(\"spam_test_ae_compressed_to_\" + str(encod_dim) + \"_features.csv\", index_label='id_of_the_text')\n",
    "    return 'hoi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'Label'\n",
    "encod_dim = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_sc, X_test_sc, y_train, y_test = scale_split(df_train, df_test, label)\n",
    "X_train_ae, X_test_ae = train_test_split(X_train_sc, train_size = 0.85, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 29154)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5000)              145775000 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               2500500   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5000)              2505000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 29154)             145799154 \n",
      "=================================================================\n",
      "Total params: 296,579,654\n",
      "Trainable params: 296,579,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3315 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2300/3315 [===================>..........] - ETA: 1:05 - loss: 0.2499"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "encoder = build_encoder_films(encod_dim, X_train_ae, X_test_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "encode_train_test_films_to_csv(encoder, X_train_sc, X_test_sc, y_train, y_test, encod_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
